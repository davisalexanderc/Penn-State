{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset conversion and splitting completed.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pycocotools import mask\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def convert_to_coco_format(input_file, output_file):\n",
    "    # Load the input JSON file\n",
    "    with open(input_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Initialize the COCO format dictionary\n",
    "    coco_format = {\n",
    "        \"info\": {\n",
    "            \"description\": data[\"info\"][\"description\"],\n",
    "            \"version\": data[\"info\"][\"version\"],\n",
    "            \"year\": 2024,\n",
    "            \"contributor\": \"Alex Davis\",\n",
    "            \"date_created\": \"2024-07-26\"\n",
    "        },\n",
    "        \"licenses\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"name\": \"CC BY 4.0\",\n",
    "                \"url\": \"http://creativecommons.org/licenses/by/4.0/\"\n",
    "            }\n",
    "        ],\n",
    "        \"categories\": [],\n",
    "        \"images\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "    \n",
    "    # Add categories\n",
    "    for category in data[\"categories\"]:\n",
    "        coco_format[\"categories\"].append({\n",
    "            \"id\": category[\"id\"],\n",
    "            \"name\": category[\"name\"],\n",
    "            \"supercategory\": \"none\"\n",
    "        })\n",
    "    \n",
    "    # Add images\n",
    "    for image in data[\"images\"]:\n",
    "        coco_format[\"images\"].append({\n",
    "            \"id\": image[\"id\"],\n",
    "            \"file_name\": image[\"file_name\"],\n",
    "            \"height\": image[\"height\"],\n",
    "            \"width\": image[\"width\"],\n",
    "            \"license\": 1,\n",
    "            \"date_captured\": \"2024-07-26 00:00:00\"\n",
    "        })\n",
    "    \n",
    "    # Function to decode RLE to polygon\n",
    "    def rle_to_polygon(rle):\n",
    "        binary_mask = mask.decode(rle)\n",
    "        polygons = []\n",
    "        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for contour in contours:\n",
    "            if contour.size >= 6:\n",
    "                polygon = contour.flatten().tolist()\n",
    "                polygons.append(polygon)\n",
    "        return polygons\n",
    "    \n",
    "    # Add annotations\n",
    "    for annotation in data[\"annotations\"]:\n",
    "        rle = annotation[\"segmentation\"]\n",
    "        if isinstance(rle, dict) and 'counts' in rle and 'size' in rle:\n",
    "            segmentation = rle_to_polygon(rle)\n",
    "        else:\n",
    "            segmentation = rle\n",
    "        coco_format[\"annotations\"].append({\n",
    "            \"id\": annotation[\"id\"],\n",
    "            \"image_id\": annotation[\"image_id\"],\n",
    "            \"category_id\": annotation[\"category_id\"],\n",
    "            \"segmentation\": segmentation,\n",
    "            \"area\": annotation[\"area\"],\n",
    "            \"bbox\": annotation[\"bbox\"],\n",
    "            \"iscrowd\": annotation[\"iscrowd\"]\n",
    "        })\n",
    "    \n",
    "    # Save the COCO format JSON to output file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(coco_format, f, separators=(',', ':'))\n",
    "    \n",
    "    return coco_format\n",
    "\n",
    "def split_dataset(coco_format, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "    # Extract all image IDs\n",
    "    image_ids = [image[\"id\"] for image in coco_format[\"images\"]]\n",
    "    \n",
    "    # Split the image IDs into train, val, and test\n",
    "    train_ids, temp_ids = train_test_split(image_ids, test_size=(1 - train_ratio))\n",
    "    val_ids, test_ids = train_test_split(temp_ids, test_size=(test_ratio / (val_ratio + test_ratio)))\n",
    "    \n",
    "    # Function to filter annotations based on image IDs\n",
    "    def filter_annotations(ids):\n",
    "        return [ann for ann in coco_format[\"annotations\"] if ann[\"image_id\"] in ids]\n",
    "    \n",
    "    # Create the subsets\n",
    "    train_data = {\n",
    "        \"info\": coco_format[\"info\"],\n",
    "        \"licenses\": coco_format[\"licenses\"],\n",
    "        \"categories\": coco_format[\"categories\"],\n",
    "        \"images\": [img for img in coco_format[\"images\"] if img[\"id\"] in train_ids],\n",
    "        \"annotations\": filter_annotations(train_ids)\n",
    "    }\n",
    "    \n",
    "    val_data = {\n",
    "        \"info\": coco_format[\"info\"],\n",
    "        \"licenses\": coco_format[\"licenses\"],\n",
    "        \"categories\": coco_format[\"categories\"],\n",
    "        \"images\": [img for img in coco_format[\"images\"] if img[\"id\"] in val_ids],\n",
    "        \"annotations\": filter_annotations(val_ids)\n",
    "    }\n",
    "    \n",
    "    test_data = {\n",
    "        \"info\": coco_format[\"info\"],\n",
    "        \"licenses\": coco_format[\"licenses\"],\n",
    "        \"categories\": coco_format[\"categories\"],\n",
    "        \"images\": [img for img in coco_format[\"images\"] if img[\"id\"] in test_ids],\n",
    "        \"annotations\": filter_annotations(test_ids)\n",
    "    }\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = './export_coco-instance_davis_alexander_TEM_Project4_TEM_V02.json'\n",
    "output_file = './coco_format_dataset.json'\n",
    "\n",
    "# Convert the dataset\n",
    "coco_format = convert_to_coco_format(input_file, output_file)\n",
    "\n",
    "# Split the dataset\n",
    "train_data, val_data, test_data = split_dataset(coco_format)\n",
    "\n",
    "# Save the splits\n",
    "with open('./train_annotations.json', 'w') as f:\n",
    "    json.dump(train_data, f, separators=(',', ':'))\n",
    "with open('./val_annotations.json', 'w') as f:\n",
    "    json.dump(val_data, f, separators=(',', ':'))\n",
    "with open('./test_annotations.json', 'w') as f:\n",
    "    json.dump(test_data, f, separators=(',', ':'))\n",
    "\n",
    "print(\"Dataset conversion and splitting completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
